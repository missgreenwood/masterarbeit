I. Indexstrukturen
------------------

1. Sakuma2011

	a. Ziel: Baumstruktur für Bloom-Filter

	* Management-Methoden (Einfügen + Löschen/"Participation" + "Secession", vgl. S. 319) f. den Baum beruhen auf Ähnlichkeitsverhältnis der Knoten/Bloom-Filter: "similar Bloom filters are grouped and managed as the child node of one internal node" (S. 321)
	* Simulation d. "tree reconstruction cost" (S. 316)
	* Neue Methoden: 
		i. Lookup-Methode f. Bloom-Filter, basierend auf B-Baum -> hier nicht relevant
		ii. Baum-Management-Methode -> basiert auf Ähnlichkeit v. Bloom-Filtern ("similarity of Bloom filter", S. 316)
	* Bloom-Filter werden als B-Baum strukturiert ("Bloom filter management method based on a B-tree", S. 316)
	* Jeder Knoten managt einen vereinigten Bloom-Filter der darunter liegenden Knoten -> der Wurzelknoten hat damit Informationen über alle (vgl. Fig. 5 S. 320) 
	* Die physischen Knoten sind natürlich nicht selbst im Baum gespeichert, sondern ihre IDs bilden logische Knoten im Baum; unterscheide zw. Verwaltung d. logischen Knoten u. Verwaltung d. Bloom-Filter!
	* Häufige Umstrukturierungen der B-Bäume sind teuer (vgl. S. 316)
	* Definition Ähnlichkeit von Bloom-Filtern (hier): #1-Bits > #0-Bits (falls #1-Bits gleich, wird der Filter umgekehrt und die #0-Bits mit AND verglichen)
	* "Node join": Ein neuer Filter kommt zu dem Knoten, mit dem er die größte Ähnlichkeit hat (vom Wurzelknoten nach unten bis zum niedrigsten inneren Knotenlevel, S. 321)
	* Auch Verschmelzen/Split von Knoten werden basierend auf Ähnlichkeit durchgeführt (vgl. S. 321f.)
	* Ergebnis Evaluation (vgl. S. 322f.): Rekonstruktionskosten können m. ähnlichkeitsbasiertem Ansatz ggü. naivem Ansatz um 9-16% reduziert werden 

	b. Von Interesse: 
		i. Falls Baumstruktur sich auch auf ein und demselben Host realisieren lässt
		ii. Verwaltung d. Bloom-Filter im Baum (Einfügen, Löschen, Nachbarinformationen, Lookup von Informationen, Update-Propagierung)  

	c. Zusammenfassung: 
		i. Vorteil: obere Schranke f. #Schritte Query-Forwarding
		ii. Nachteil: Baumstruktur muss aufgebaut werden 
		iii. Baumhöhe ändert sich dynamisch je nach Knotenanzahl 
		iv. Repräsentative Knoten managen Maintenance-Informationen u. propagieren die Queries 
		v. #Rekonstruktionen -> werden durch Methode reduziert -> gut für Netzwerk mit häufigem join/leave von Knoten


2. Yang2002

	a. Ziel: Neue Indexstruktur f. versch. Join-Anfragen auf mulitidimensionalen spatialen Daten ("k-closest pairs", "nearest neighbor joins") -> "bichromatic Rdnn-Tree [...] to solve the closest pair join problem" (S. 141)
	
	* Basiert auf "Rdnn-tree for the reverse nearest neighbor queries" (S. 140)
	* Besonders effektiv f. "k-closest pair"-Anfragen, v. a. ggü. früheren Implementierungen wie R*-Baum
	* Wichtige Anfragen (auf multidimensionalen spatialen Daten): "point location, range, nearest neighbor, reverse nearest neighbor" (S. 140) -> es werden behandelt: 
		i. "(Distance-based) Spatial Joins" (S. 140) 
	* Wichtigste/effizienteste Algorithmen basieren auf: R-Bäumen, Seed-Bäumen, Breadth-First-approach 
		ii. "k Closest nearest neighbor pairs" (S. 140)
		iii. "k Closest pairs"
	* bRdnn-Tree verwendet Information über die nächsten Nachbarn, um Suchpfade abzuschneiden 
	* Behandelte Probleme/Fragestellungen: "nearest neighbor related problems" (S. 141), also 
		i. "Bichromatic Nearest Neighbor Query" (S. 141)
		ii. "k Closest NN Pairs Query" (S. 141)
		iii. "k-Closest Pair Join" (S. 141)
	* Zusammenhang: Jedes "Closest Pair" in den "k-closest NN pairs" enthalten (vgl. S. 142)
	* Neue Datenstruktur bRdnn-Tree: 
		i. Grundidee: Verwende Lösung des k-closest NN pair-Problems, um k-closest pairs zu finden (vgl. Theorem 2.1, S. 141)
		ii. Wichtigster Aspekt: Die Information über das NN pair wird dynamisch im Baum gespeichert 
		iii. Beruht auf dem Rdnn-Baum, der das "Reverse Nearest Neighbor Problem" löst (S. 143) -> dieses Problem ist eigentlich bzgl. EINER Menge definiert: "Recall that the reverse nearest neighbor (RNN) of a point p in a data set S is a collection of points in S that have p as their nearest neighbor" (S. 143) -> also müsste ich eigentlich alle Algorithmen analog anwenden können, indem ich einfach nur EINEN Baum aufbaue und die Vergleiche im Inneren stattfinden lasse!
		iv. Innere Knoten in beiden Bäumen enthalten Einträge der Form (ptr, Rect, max_dnn, min_dnn): ptr ist die Adresse eines Kindknotens; falls ptr auf ein Blatt verweist, ist Rect das MBR aller Punkte im Blattknoten/falls ptr auf einen weiteren inneren Knoten verweist, ist Rect das MBR aller MBRs im Kindknoten; max_dnn/min_dnn sind die maximale/minimale Distanz jedes Punktes zu seinem NN in der anderen Menge -> müsste ich also entsprechend anpassen
	* Def. d. Kosten (f. Suche): Durchschnittliche #Blattknoten-Zugriffe  
	* Beste Ergebnisse bei kleinem k (vgl. S. 145)
	* Der R*-Baum wird vor allem übertroffen, da: "by storing the nearest neighbor distance, our method can prune each bRdnn-Tree index separately at high level" (S. 145)
	
	b. Von Interesse: 
		i. Alternative Indexstrukturen: "the index structure is also very efficient on [...] closest nearest neighbor pairs, and all pairs nearest neighbor" (S. 141)
		iii. Im Prinzip geht es hier immer um den Vergleich von Elementen zweier Mengen; ich möchte aber Aussagen über Elemente aus EINER Menge treffen (hier nämlich das Ziel: "new indexing scheme for join queries over multiple data sets", S. 142)

	c. Zusammenfassung:
		i. "in a relatively static environment with a relatively small data set, it is appropriate to use the naive nested-loop algorithm and cache the closest pairs. However, in a dynamic environment or with large amount of data, it is preferable to use the bRdnn-tree" (S. 148)
		ii. Vorstellung des bRdnn-Baums für Join-Queries
		iii. Indexstruktur speichert die NN-Distanz f. jeden Datenpunkt 
		iv. Liefert Pruning-Methode f. zahlreiche Anfragen (k-nächste Paare, k-NN-Paare)
		v. Index ist robust sowohl f. unterschiedliche Verteilungen der Daten als auch begrenzte Ressourcen 


II. Algorithmen 
---------------

1. Bayardo2007

	a. Ziel: 
		i. Gegeben: Große Menge dünn verteilter Vektordaten in hochdimensionalem Raum 
		ii. Problemstellung: Finde alle Paare mit Ähnlichkeitswert über einer bestimmten Schwelle (Ähnlichkeitsmaß: z.B. Kosinusdistanz)
		iii. Lösung: Einfacher Algorithmus basierend auf neuer Indexstruktur und Optimierung, ohne Näherungsverfahren oder komplexes Parameter-Tuning ("We show the approach efficiently handles a variety of datasets across a wide setting of similarity thresholds, with large speedups over previous state-of-the-art approaches" (S. 131))
		iv. Problembeschreibung: "Given a set of real-valued vectors V [...] of fixed dimensionality m, a similarity function sim(x,y) and a similarity threshold t, we wish to compute the set of all pairs (x,y) and their similarity values sim(x,y) such that x,y ∈ V and sim(x,y) ≥ t" (S. 131)

	* Heute i.d.R.: Näherungsverfahren -> hohe Fehlerraten/exakte Lösungen, aber in DBMS-Framework!   
	* Hier stattdessen: Keine DBMS-Integration, Fokus rein auf Performance 
	* "The all-pairs similarity search problem is a generalization of the well-known nearest neighbor problem in which the goal is to find the nearest neighbors of a given point query" (S. 132)
	* Lösungsansätze mit Näherungsverfahren: Reduktion d. Dimensionalität und/oder Länge d. Input-Vektoren 
	* Das Problem wird in der DB-Community allgemein als "similarity join problem" bezeichnet (S. 132) -> zwei Ansätze: "inverted list solutions" u. "signature based solutions" (S. 132)

	1. Verbesserung des naiven Ansatzes: Berechne Index dynamisch [vgl. Sarawagi2004], speichere Gewichte der Vektoren im invertierten Index mit ab -> "Score accumulation can then be applied to compute the similarity function using the inverted index structure alone" (S. 132) -> All-Pairs-0

	2. Verbesserung: Schwellwert kann verwendet werden, um Kandidatenpaare einzugrenzen; vermeide Aufbau des gesamten invertierten Index (wie z.B. [Sarawagi2004]) -> hier stattdessen: "exploit the threshold to reduce the amount of information indexed in the first place" (S. 132) -> All-Pairs-1 (viel schneller als All-Pairs-0, da drastische Reduzierung d. max. Größe d. invertierten Listen)

	3. Verbesserung: Ausnutzen von sortierten Listen (weitere Einschränkung d. Kandidatenmenge -> "a vector y must be produced as a candidate only when matched against those vectors that follow it in the order in which the dataset is processed" (S. 133); "The ordering over the vectors guarantees any vector x that is produced after a vector y has a lower maximum weight. Significantly fewer features of each vector can now be indexed while still guaranteeing candidacy of a vector when matched against those that follow it in the iteration order" (S. 134)) -> All-Pairs-2

	4. Verbesserung: Ausnutzen des Schwellwerts während Abgleich/Berechne nicht das gesamte Skalarprodukt über x und y ("partial candidate vector"), sondern Schranke -> "Find-Matches-2" (vgl. S. 134 Fig. 3b)

	5. Spezialisierung f. binäre Vektoren -> "All-Pairs-Binary" (vgl. S. 135 Fig. 4)
		i. Man könnte die bisher vorgestellten Algorithmen direkt verwenden, indem man die Inputs auf Einheitslänge normalisiert und auf den resultierenden gewichteten Vektoren arbeitet
		ii. Jedoch hier: Vermeide komplizierte Berechnungen + weitere Optimierungen möglich 
		iii. Bsp.: "If the vectors are binary, there is no need to store vector weights within the inverted index as long as we can get at the vector sizes in order to appropriately compute the similarity function" (S. 135)
		iv. "all vectors that fail to meet the minimum size constraint appear at the front of the list" (S. 135) -> alle diese Vektoren können sofort entfernt/übersprungen werden 
		v. für alle weiteren Vektorenpaare (x,y), deren Kosinusähnlichkeit über einem best. Schwellenwert t liegt, wird folgender "minsize constraint" ausgenutzt: |y| ≥ |x|*t^2 (S. 136)
		vi. Details u. Korrektheitsbeweis vgl. S. 135

	* Verwendete Beispieldatensätze: U. a. "the Orkut social network, in which each user is represented by a binary vector over the space of all users" (S. 136) 
	* Es wurden immer sortierte Datensätze verwendet
	* Schwellwert f. Ähnlichkeitsmaß: Zwischen 0.5 und 0.9

	b. Von Interesse: 
		i. Nur die Variante f. binäre Daten
		ii. Implementierung: vgl. https://code.google.com/archive/p/google-all-pairs-similarity-search/
		iii. Nur Portierung auf Jaccard-Distanz für mich interessant!

	c. Zusammenfassung/Ergebnisse: 
		i. PE (Part Enum): "another signature based algorithm that like All-Pairs is guaranteed to generate all pairs that satisfy the similarity threshold" (S. 138); Verwendet Konversion von Jaccard-Distanz zu Hammingabstand! (S. 138)
		ii. Vergleich mit signaturbasierten Methoden (LSH u. PartEnum): Verwendung von Jaccard-Distanz und Kosinusähnlichkeit (vgl. S. 139 Fig. 9); All-Pairs ist immer deutlich schneller: 
		iii. LSH: Faktor 16-700 bei Kosinusähnlichkeit, mind. eine Größenordnung b. Jaccard-Distanz
		iv. PE: Faktor 2-15 b. Kosinusähnlichkeit, Faktor 1.3-6 b. Jaccard-Distanz  
		v. Verallgemeinerung d. Ergebnisse f. andere Ähnlichkeitsmetriken: Algo. kann auch für andere Ähnlichkeitsmaße angewendet werden, z.B. Jaccard mit binären Eingabevektoren; notwendige Anpassungen: "For an indexed vector y and any vector x following it in the ordering (|x|≥|y|) [...] we [...] only need to show that the unindexed portion of the vector y [...] contributes an amount to the similarity score that alone is not enough to meet the threshold" (S. 139) -> "Find-Matches-Binary" muss angepasst werden bzgl. "similarity score, upperbound the similarity score, and compute a monotone minimum size constraint on candidate vectors" (S. 139)
		vi. Ergebnisse f. All-Pairs-Algo. m. anderen Ähnlichkeitsmaßen: Vgl. S. 140 Fig. 10 -> Jaccard performt immer am besten!
		vii.  "An inverted list based approach to the problem need not build a complete inverted index over the vector input" (S. 139)
		viii. "Appropriately ordering the vectors in addition to the dimensions can vastly reduce the search space" (S. 139)
		ix. "We aggressively exploited these insights to produce an algorithm, All-Pairs, that is easy to implement and does not require any parameter tuning" (S. 139) -> führt zu drastischen Performance-Steigerungen ggü. vergleichbaren Algorithmen 


III. Evaluation
---------------

	1. Wie arbeitet Cassandra stress tool?

	* "cassandra-stress supports testing arbitrary CQL tables and queries to allow users to benchmark their data model" (vgl. https://github.com/apache/cassandra/tree/trunk/tools/stress): command "user"
	* "To make testing data models simpler, we have extended the cassandra-stress tool in Cassandra 2.1 to support stress testing arbitrary CQL tables and arbitrary queries on that table. We think it will be a very useful tool for users who want to quickly see how a schema will perform." (vgl. http://www.datastax.com/dev/blog/improved-cassandra-2-1-stress-tool-benchmark-any-schema)
	* YAML: "Yet Another Multicolumn Layout" (a modular CSS framework for truly flexible, accessible and responsive websites)

	2. Wie bringe ich meine Daten in Cassandra? 

	3. Wie werden die Bloom-Filter in Cassandra generiert/eingesetzt?

	* "Cassandra uses bloom filters to save IO when performing a key lookup: each SSTable has a bloom filter associated with it that Cassandra checks before doing any disk seeks, making queries for keys that don't exist almost free" (http://spyced.blogspot.de/2009/01/all-you-ever-wanted-to-know-about.html)
	* Cassandra uses bloom filters to save IO when performing a key lookup: each [Sorted String Table] has a bloom filter associated with it that Cassandra checks before doing any disk seeks, making queries for keys that don't exist almost free (http://www.maxburstein.com/blog/creating-a-simple-bloom-filter/)
	* "Cassandra only uses the bloom filter, to find out the SST (Sorted String Table) which most likely contains the key [(a]s there might be several SSTs. [T]o speed this up looking in all SSTs bloomfilters are used" (http://stackoverflow.com/questions/5849283/bloomfilter-and-cassandra-why-used-and-why-hashed-several-times)
	* "The columns of a key may be spread out in several sstables. If it wasn't for bloom filters, every read of a key would have to read every sstable, which is prohibitively expensive. By using bloom filters, cassandra almost always only has to look in the sstables which contain data for that key" (ebd.)
	* 


	4. Cassandra Howto 

	* Launch: launchctl load ~/Library/LaunchAgents/homebrew.mxcl.cassandra.plist
	* Stop: launchctl unload ~/Library/LaunchAgents/homebrew.mxcl.cassandra.plist
	* Properties: /usr/local/etc/cassandra
	* Logs: /usr/local/var/log/cassandra
	* Data: /usr/local/var/lib/cassandra/data


